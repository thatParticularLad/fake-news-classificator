{"cells":[{"cell_type":"code","source":["import locale\n","print(locale.getpreferredencoding())\n","import locale\n","def getpreferredencoding(do_setlocale = True):\n","    return \"UTF-8\"\n","locale.getpreferredencoding = getpreferredencoding"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RcrBcJW7X8G7","executionInfo":{"status":"ok","timestamp":1684711250568,"user_tz":-180,"elapsed":7,"user":{"displayName":"Alunat","userId":"04744058558773087828"}},"outputId":"ca9f6e47-a268-4b45-f15b-71f1a51ff8b9"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["UTF-8\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive/')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m-p7wQEd7fsU","executionInfo":{"status":"ok","timestamp":1684711273595,"user_tz":-180,"elapsed":23032,"user":{"displayName":"Alunat","userId":"04744058558773087828"}},"outputId":"8106c9b4-7108-46de-f01a-96ab79e2d22b"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}]},{"cell_type":"code","source":["!ls \"/content/drive/My Drive/nlp\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_atJBANA8K5l","executionInfo":{"status":"ok","timestamp":1684711274703,"user_tz":-180,"elapsed":1113,"user":{"displayName":"Alunat","userId":"04744058558773087828"}},"outputId":"31fc7c0d-46df-46eb-d6f5-4c30ade46538"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["cleaned-kaggle2.csv\t\tglove_twitter\n","cleaned-proppy2.csv\t\tmodels\n","cleaned-wellfake2.csv\t\tprepped-data\n","data\t\t\t\twellfake_lr_title_vectorizer.pickle\n","fake_news_classification.ipynb\n"]}]},{"cell_type":"code","source":["import os\n","current_dir = \"/content/drive/MyDrive/nlp\"\n","os.chdir(\"/content/drive/MyDrive/nlp\") "],"metadata":{"id":"tOSa55m8YZBt","executionInfo":{"status":"ok","timestamp":1684711274704,"user_tz":-180,"elapsed":19,"user":{"displayName":"Alunat","userId":"04744058558773087828"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["!pwd"],"metadata":{"id":"iW9xA1pu8agb","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684711274705,"user_tz":-180,"elapsed":19,"user":{"displayName":"Alunat","userId":"04744058558773087828"}},"outputId":"a06662bc-8b6f-4921-e2d5-8c28f8ae440e"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/nlp\n"]}]},{"cell_type":"code","source":["!pip install -q keras"],"metadata":{"id":"-3jv9u2U8T6q","executionInfo":{"status":"ok","timestamp":1684711278048,"user_tz":-180,"elapsed":3351,"user":{"displayName":"Alunat","userId":"04744058558773087828"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"db9fGvd1Hj-k","outputId":"b7048d30-0d1f-40e6-f67e-c9592e3a5ce8","executionInfo":{"status":"ok","timestamp":1684711305456,"user_tz":-180,"elapsed":27414,"user":{"displayName":"Alunat","userId":"04744058558773087828"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]},{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (3.20.3)\n","Collecting protobuf\n","  Downloading protobuf-4.23.1-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.5/304.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: protobuf\n","  Attempting uninstall: protobuf\n","    Found existing installation: protobuf 3.20.3\n","    Uninstalling protobuf-3.20.3:\n","      Successfully uninstalled protobuf-3.20.3\n","Successfully installed protobuf-4.23.1\n"]}],"source":["# setup\n","import sys\n","import subprocess\n","import re\n","import os\n","import spacy\n","import numpy as np\n","import pandas as pd\n","import pickle\n","\n","\n","from bs4 import BeautifulSoup\n","from spacy.lang.en import English\n","\n","import en_core_web_sm\n","nlp = en_core_web_sm.load()\n","\n","import nltk\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","\n","stop_words = set(stopwords.words('english'))\n","\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n","\n","\n","#Importuojame paketus\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.multiclass import OneVsRestClassifier\n","from sklearn.naive_bayes import MultinomialNB\n","from sklearn.svm import LinearSVC\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.pipeline import Pipeline\n","from sklearn.metrics import accuracy_score\n","from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n","\n","!pip install --upgrade protobuf\n","\n","import keras\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","from keras.preprocessing import text, sequence\n","from keras.models import Sequential\n","from keras.layers import Dense,Embedding,LSTM,Dropout\n","from keras.callbacks import ReduceLROnPlateau"]},{"cell_type":"code","source":["print(\"Version: \", tf.__version__)\n","print(\"Eager mode: \", tf.executing_eagerly())\n","print(\"Hub version: \", hub.__version__)\n","print(\"GPU is\", \"available\" if tf.config.list_physical_devices('GPU') else \"NOT AVAILABLE\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qKXY5StfMavJ","executionInfo":{"status":"ok","timestamp":1684711305457,"user_tz":-180,"elapsed":29,"user":{"displayName":"Alunat","userId":"04744058558773087828"}},"outputId":"005a63a4-9d8e-4c4b-a9dc-e7c0852e9909"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["Version:  2.12.0\n","Eager mode:  True\n","Hub version:  0.13.0\n","GPU is available\n"]}]},{"cell_type":"markdown","metadata":{"id":"8OYli4R72fZS"},"source":["## Importuojame išvalytus duomenis"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"UwqVESLT2fZe","outputId":"36a80b72-7b79-4b53-d7c1-aabaeb206cc2","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1684711310589,"user_tz":-180,"elapsed":5154,"user":{"displayName":"Alunat","userId":"04744058558773087828"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   label                                              title  \\\n","0      1   Donald Trump Sends Out Embarrassing New Year’...   \n","1      1   Drunk Bragging Trump Staffer Started Russian ...   \n","2      1   Sheriff David Clarke Becomes An Internet Joke...   \n","3      1   Trump Is So Obsessed He Even Has Obama’s Name...   \n","4      1   Pope Francis Just Called Out Donald Trump Dur...   \n","\n","                                                text  \\\n","0  Donald Trump just couldn t wish all Americans ...   \n","1  House Intelligence Committee Chairman Devin Nu...   \n","2  On Friday, it was revealed that former Milwauk...   \n","3  On Christmas day, Donald Trump announced that ...   \n","4  Pope Francis used his annual Christmas Day mes...   \n","\n","                                        cleaned_text  \\\n","0  donald trump wish american happy new year leav...   \n","1  house intelligence committee chairman devin nu...   \n","2  friday revealed former milwaukee sheriff david...   \n","3  christmas day donald trump announced would bac...   \n","4  pope francis used annual christmas day message...   \n","\n","                                       cleaned_title  \n","0  donald trump sends embarrassing new year eve m...  \n","1  drunk bragging trump staffer started russian c...  \n","2  sheriff david clarke becomes internet joke thr...  \n","3  trump obsessed even obamas name coded website ...  \n","4  pope francis called donald trump christmas speech  "],"text/html":["\n","  <div id=\"df-5f16ec5e-7c24-4bf5-8c4c-73d2673c415a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>title</th>\n","      <th>text</th>\n","      <th>cleaned_text</th>\n","      <th>cleaned_title</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n","      <td>Donald Trump just couldn t wish all Americans ...</td>\n","      <td>donald trump wish american happy new year leav...</td>\n","      <td>donald trump sends embarrassing new year eve m...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n","      <td>House Intelligence Committee Chairman Devin Nu...</td>\n","      <td>house intelligence committee chairman devin nu...</td>\n","      <td>drunk bragging trump staffer started russian c...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n","      <td>On Friday, it was revealed that former Milwauk...</td>\n","      <td>friday revealed former milwaukee sheriff david...</td>\n","      <td>sheriff david clarke becomes internet joke thr...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n","      <td>On Christmas day, Donald Trump announced that ...</td>\n","      <td>christmas day donald trump announced would bac...</td>\n","      <td>trump obsessed even obamas name coded website ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n","      <td>Pope Francis used his annual Christmas Day mes...</td>\n","      <td>pope francis used annual christmas day message...</td>\n","      <td>pope francis called donald trump christmas speech</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f16ec5e-7c24-4bf5-8c4c-73d2673c415a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-5f16ec5e-7c24-4bf5-8c4c-73d2673c415a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-5f16ec5e-7c24-4bf5-8c4c-73d2673c415a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":9}],"source":["kaggle_data = pd.read_csv('prepped-data/cleaned-kaggle2.csv')\n","kaggle_data.dropna(inplace = True)\n","kaggle_data.head()\n"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"0CFponAx2fZe","outputId":"d0e9e2f7-6875-4851-8246-1a77240db819","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1684711316304,"user_tz":-180,"elapsed":5732,"user":{"displayName":"Alunat","userId":"04744058558773087828"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                               title  \\\n","0  UNBELIEVABLE! OBAMAS ATTORNEY GENERAL SAYS MOS...   \n","1  Bobby Jindal, raised Hindu, uses story of Chri...   \n","2  SATAN 2: Russia unvelis an image of its terrif...   \n","3  DR BEN CARSON TARGETED BY THE IRS: I never had...   \n","5  Sports Bar Owner Bans NFL GamesWill Show Only ...   \n","\n","                                                text  label  \\\n","0   Now, most of the demonstrators gathered last ...      1   \n","1  A dozen politically active pastors came here f...      0   \n","2  The RS-28 Sarmat missile, dubbed Satan 2, will...      1   \n","3  DR. BEN CARSON TELLS THE STORY OF WHAT HAPPENE...      1   \n","5  The owner of the Ringling Bar, located south o...      1   \n","\n","                                        cleaned_text  \\\n","0  demonstrator gathered last night exercising co...   \n","1  dozen politically active pastor came private d...   \n","2  r sarmat missile dubbed satan replace s fly mi...   \n","3      dr ben carson tell story happened spoke obama   \n","5  owner ringling bar located south white sulphur...   \n","\n","                                       cleaned_title  \n","0  unbelievable obamas attorney general say charl...  \n","1  bobby jindal raised hindu us story christian c...  \n","2  satan russia unvelis image terrifying new supe...  \n","3  dr ben carson targeted irs never audit spoke n...  \n","5  sport bar owner ban nfl gameswill show true am...  "],"text/html":["\n","  <div id=\"df-2af4fc57-160b-4d33-9ce5-313cc5cf12e6\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>title</th>\n","      <th>text</th>\n","      <th>label</th>\n","      <th>cleaned_text</th>\n","      <th>cleaned_title</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>UNBELIEVABLE! OBAMAS ATTORNEY GENERAL SAYS MOS...</td>\n","      <td>Now, most of the demonstrators gathered last ...</td>\n","      <td>1</td>\n","      <td>demonstrator gathered last night exercising co...</td>\n","      <td>unbelievable obamas attorney general say charl...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Bobby Jindal, raised Hindu, uses story of Chri...</td>\n","      <td>A dozen politically active pastors came here f...</td>\n","      <td>0</td>\n","      <td>dozen politically active pastor came private d...</td>\n","      <td>bobby jindal raised hindu us story christian c...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>SATAN 2: Russia unvelis an image of its terrif...</td>\n","      <td>The RS-28 Sarmat missile, dubbed Satan 2, will...</td>\n","      <td>1</td>\n","      <td>r sarmat missile dubbed satan replace s fly mi...</td>\n","      <td>satan russia unvelis image terrifying new supe...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>DR BEN CARSON TARGETED BY THE IRS: I never had...</td>\n","      <td>DR. BEN CARSON TELLS THE STORY OF WHAT HAPPENE...</td>\n","      <td>1</td>\n","      <td>dr ben carson tell story happened spoke obama</td>\n","      <td>dr ben carson targeted irs never audit spoke n...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Sports Bar Owner Bans NFL GamesWill Show Only ...</td>\n","      <td>The owner of the Ringling Bar, located south o...</td>\n","      <td>1</td>\n","      <td>owner ringling bar located south white sulphur...</td>\n","      <td>sport bar owner ban nfl gameswill show true am...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2af4fc57-160b-4d33-9ce5-313cc5cf12e6')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-2af4fc57-160b-4d33-9ce5-313cc5cf12e6 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-2af4fc57-160b-4d33-9ce5-313cc5cf12e6');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":10}],"source":["wellfake_data = pd.read_csv('prepped-data/cleaned-wellfake2.csv')\n","wellfake_data.dropna(inplace = True)\n","wellfake_data.head()"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"e3SCXR9P2fZf","outputId":"2c401db3-0352-4525-80b4-1a45de15af05","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1684711323860,"user_tz":-180,"elapsed":7566,"user":{"displayName":"Alunat","userId":"04744058558773087828"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                text  \\\n","0  Convened to examine the causes of civil unrest...   \n","1  Discriminating against someone on the basis of...   \n","2  Bill Cosby's 44-year-old daughter, Ensa Cosby,...   \n","3  The fast-moving, powerful theatrical locomotiv...   \n","4  It's Friday. It's National Pizza Day. Grab lif...   \n","\n","                                               title  label  \\\n","0  Report: No progress for African-Americans on h...    0.0   \n","1  Employers can't discriminate based on sexual o...    0.0   \n","2  Bill Cosby's daughter Ensa, 44, dies in Massac...    0.0   \n","3  'Murder On The Orient Express' A Funny, Fast-P...    0.0   \n","4    You Can Celebrate National Pizza Day Right Here    0.0   \n","\n","                                        cleaned_text  \\\n","0  convened examine cause civil unrest black comm...   \n","1  discriminating someone basis sexual orientatio...   \n","2  bill cosbys yearold daughter ensa cosby died m...   \n","3  fastmoving powerful theatrical locomotive murd...   \n","4  friday national pizza day grab life slice conn...   \n","\n","                                       cleaned_title  \n","0  report progress africanamericans homeownership...  \n","1  employer cant discriminate based sexual orient...  \n","2         bill cosbys daughter ensa dy massachusetts  \n","3  murder orient express funny fastpaced thrill r...  \n","4                 celebrate national pizza day right  "],"text/html":["\n","  <div id=\"df-7c4711a3-5546-45b8-b051-c7b1e8898329\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>title</th>\n","      <th>label</th>\n","      <th>cleaned_text</th>\n","      <th>cleaned_title</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Convened to examine the causes of civil unrest...</td>\n","      <td>Report: No progress for African-Americans on h...</td>\n","      <td>0.0</td>\n","      <td>convened examine cause civil unrest black comm...</td>\n","      <td>report progress africanamericans homeownership...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Discriminating against someone on the basis of...</td>\n","      <td>Employers can't discriminate based on sexual o...</td>\n","      <td>0.0</td>\n","      <td>discriminating someone basis sexual orientatio...</td>\n","      <td>employer cant discriminate based sexual orient...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Bill Cosby's 44-year-old daughter, Ensa Cosby,...</td>\n","      <td>Bill Cosby's daughter Ensa, 44, dies in Massac...</td>\n","      <td>0.0</td>\n","      <td>bill cosbys yearold daughter ensa cosby died m...</td>\n","      <td>bill cosbys daughter ensa dy massachusetts</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>The fast-moving, powerful theatrical locomotiv...</td>\n","      <td>'Murder On The Orient Express' A Funny, Fast-P...</td>\n","      <td>0.0</td>\n","      <td>fastmoving powerful theatrical locomotive murd...</td>\n","      <td>murder orient express funny fastpaced thrill r...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>It's Friday. It's National Pizza Day. Grab lif...</td>\n","      <td>You Can Celebrate National Pizza Day Right Here</td>\n","      <td>0.0</td>\n","      <td>friday national pizza day grab life slice conn...</td>\n","      <td>celebrate national pizza day right</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c4711a3-5546-45b8-b051-c7b1e8898329')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-7c4711a3-5546-45b8-b051-c7b1e8898329 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-7c4711a3-5546-45b8-b051-c7b1e8898329');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":11}],"source":["proppy_data = pd.read_csv('prepped-data/cleaned-proppy2.csv')\n","proppy_data.dropna(inplace = True)\n","proppy_data.head()"]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","def word_count_plot(df, col='cleaned_text'):\n","    # Set the style to grayscale\n","    sns.set(style='white', palette='gray')\n","\n","    # Create the subplots\n","    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n","\n","    # Plot histogram for fake news\n","    text_len_fake = df[df['label'] == 0][col].str.split().map(lambda x: len(x))\n","    ax1.hist(text_len_fake, bins=30, color='lightgray', edgecolor='black')\n","    ax1.set_title('Fake News')\n","    ax1.set_xlabel('Word Count')\n","    ax1.set_ylabel('Frequency')\n","    ax1.set_xticks(range(0, max(text_len_fake) + 1, 250))  # Set x-axis ticks with spacing of 250\n","    ax1.tick_params(axis='x', rotation=90)  # Rotate x-axis tick labels by 90 degrees\n","\n","   \n","\n","    # Plot histogram for real news\n","    text_len_real = df[df['label'] == 1][col].str.split().map(lambda x: len(x))\n","    ax2.hist(text_len_real, bins=30, color='lightgray', edgecolor='black')\n","    ax2.set_title('Real News')\n","    ax2.set_xlabel('Word Count')\n","    ax2.set_ylabel('Frequency')\n","    ax2.set_xticks(range(0, max(text_len_real) + 1, 250))  # Set x-axis ticks with spacing of 250\n","    ax2.tick_params(axis='x', rotation=90)  # Rotate x-axis tick labels by 90 degrees\n","\n","       # Calculate and log average word count\n","    avg_fake = sum(text_len_fake) / len(text_len_fake)\n","    avg_real = sum(text_len_real) / len(text_len_real)\n","    plt.text(0.5, -0.15, f'Average Word Count (Fake News): {avg_fake:.2f}\\nAverage Word Count (Real News): {avg_real:.2f}',\n","             horizontalalignment='center', verticalalignment='center', transform=ax2.transAxes)\n","    \n","\n","    # Set the title\n","    fig.suptitle(f'Words in {col}', fontsize=16, fontweight='bold')\n","\n","    # Remove spines\n","    sns.despine()\n","\n","    # Display the plot\n","    plt.tight_layout()\n","    plt.show()"],"metadata":{"id":"-5Z8J2RKnibr","executionInfo":{"status":"ok","timestamp":1684713731378,"user_tz":-180,"elapsed":496,"user":{"displayName":"Alunat","userId":"04744058558773087828"}}},"execution_count":51,"outputs":[]},{"cell_type":"markdown","source":["## Get word length"],"metadata":{"id":"JBOcRD4AylWS"}},{"cell_type":"code","source":["def word_length_plot(df, col='cleaned_text'):\n","    # Set the style to grayscale\n","    sns.set(style='white', palette='gray')\n","\n","    # Create the subplots\n","    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n","\n","    # Plot histogram for original text\n","    word_original = df[df['label'] == 1][col].str.split().apply(lambda x: [len(i) for i in x if len(i) <= 7])\n","    sns.distplot(word_original.map(lambda x: np.mean(x)), ax=ax1, color='gray')\n","    ax1.set_title('Original Text')\n","    ax1.set_xlabel('Average Word Length')\n","    ax1.set_ylabel('Density')\n","\n","    # Plot histogram for fake text\n","    word_fake = df[df['label'] == 0][col].str.split().apply(lambda x: [len(i) for i in x if len(i) <= 7])\n","    sns.distplot(word_fake.map(lambda x: np.mean(x)), ax=ax2, color='gray')\n","    ax2.set_title('Fake Text')\n","    ax2.set_xlabel('Average Word Length')\n","    ax2.set_ylabel('Density')\n","\n","    # Set the title\n","    fig.suptitle('Average Word Length in Each Text', fontsize=16, fontweight='bold')\n","\n","    # Remove spines\n","    sns.despine()\n","\n","    # Display the plot\n","    plt.tight_layout()\n","    plt.show()"],"metadata":{"id":"OibLTKh1yePo","executionInfo":{"status":"ok","timestamp":1684715141576,"user_tz":-180,"elapsed":2,"user":{"displayName":"Alunat","userId":"04744058558773087828"}}},"execution_count":75,"outputs":[]},{"cell_type":"markdown","source":["### Created a combined attribute from main text and title"],"metadata":{"id":"ujZSIyB5xSW1"}},{"cell_type":"code","source":["kaggle_data['cleaned_combined'] = kaggle_data['title'] + ' ' + kaggle_data['text']\n","wellfake_data['cleaned_combined'] = wellfake_data['title'] + ' ' + wellfake_data['text']\n","# proppy_data['cleaned_combined'] = proppy_data['title'] + ' ' + proppy_data['text']\n"],"metadata":{"id":"UinN7-B9xRk3","executionInfo":{"status":"ok","timestamp":1684711324370,"user_tz":-180,"elapsed":524,"user":{"displayName":"Alunat","userId":"04744058558773087828"}}},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":["#### Train-test-split, vectorization"],"metadata":{"id":"1OXIibxMXhM4"}},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split\n","import pickle\n","\n","# Can also be 'cleaned_title', 'cleaned_combined' or 'cleaned_text'\n","# returns: X_train, X_test, y_train, y_test\n","def create_train_test_split(dataset, attribute):\n","  x = getattr(dataset, attribute)\n","  y = dataset['label']\n","  return train_test_split(x, y, test_size=0.20, shuffle=True, random_state=0)  \n","\n","def vectorize(vectorizer, x_train, x_test,filename):\n","  x_train_vect = vectorizer.fit_transform(x_train)\n","  x_test_vect = vectorizer.transform(x_test)\n","  \n","  # save vectorizer\n","  vec_filename = f'{filename}_vectorizer.pickle'\n","  pickle.dump(vectorizer, open(f'models/{vec_filename}', 'wb'))\n","\n","  return x_train_vect, x_test_vect"],"metadata":{"id":"yYysSABPXjf3","executionInfo":{"status":"ok","timestamp":1684711331531,"user_tz":-180,"elapsed":3,"user":{"displayName":"Alunat","userId":"04744058558773087828"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["#### Classical ML utils"],"metadata":{"id":"4wunk9dEXrxp"}},{"cell_type":"code","source":["from sklearn.metrics import classification_report, confusion_matrix\n","from joblib import dump\n","\n","\n","# Classical ML \n","def train_classical_model(model, x_train, y_train, x_test, y_test):\n","  model.fit(x_train, y_train)\n","  y_pred = model.predict(x_test)\n","  acc = accuracy_score(y_test, y_pred)\n","  # Evaluate model\n","  print(\"Accuracy:\", acc)\n","  target_names = ['True', 'Fake']\n","  print(classification_report(y_test, y_pred, target_names=target_names, digits=3))\n","\n","  tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n","  specificity = tn / (tn+fp)\n","  print(f'Specificity {specificity}')\n","  # Save model \n","\n","def save_classical_model(model, filename):\n","  dump(model, f'models/{filename}.joblib') \n","  print(f'Model {filename} saved!')\n","\n","\n","# Combining function\n","def train_and_eval_model(dataset, attribute, vectorizer, model, filename='classical_model'):\n","  x_train, x_test, y_train, y_test = create_train_test_split(dataset, attribute)\n","  x_train_vect, x_test_vect = vectorize(vectorizer, x_train, x_test, filename)\n","  train_classical_model(model, x_train_vect, y_train, x_test_vect, y_test)\n","  save_classical_model(model, filename)"],"metadata":{"id":"JsFbnJqCXyZK","executionInfo":{"status":"aborted","timestamp":1684711324371,"user_tz":-180,"elapsed":16,"user":{"displayName":"Alunat","userId":"04744058558773087828"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#### Deep learning utils"],"metadata":{"id":"4VeowtWng85H"}},{"cell_type":"code","source":["GLOVE_EMBEDDING = \"./glove_twitter/glove.twitter.27B.100d.txt\""],"metadata":{"id":"SQ5Z4HEH5vF_","executionInfo":{"status":"aborted","timestamp":1684711324372,"user_tz":-180,"elapsed":16,"user":{"displayName":"Alunat","userId":"04744058558773087828"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.utils import pad_sequences\n","from keras.preprocessing.text import Tokenizer\n","\n","def get_coefs(word, *arr):\n","    return word, np.asarray(arr, dtype = \"float32\")\n","\n","\n","def tokenize(x_train, x_test):\n","  tokenizer = Tokenizer(num_words = 10000)\n","  tokenizer.fit_on_texts(x_train)\n","  tokenized_train = tokenizer.texts_to_sequences(x_train)\n","  tokenized_test = tokenizer.texts_to_sequences(x_test)\n","\n","  x_train = pad_sequences(tokenized_train, maxlen = 300)\n","  x_test = pad_sequences(tokenized_test, maxlen = 300)\n","  return x_train, x_test, tokenizer\n","\n","\n","def generate_embedding_matrix(tokenizer):\n","\n","  embeddings_index = dict(get_coefs(*g.rstrip().rsplit(\" \")) for g in open(GLOVE_EMBEDDING, errors=\"ignore\"))\n","  embeddings = np.stack(embeddings_index.values())\n","  embedding_mean, embedding_std = embeddings.mean(), embeddings.std()\n","  embedding_size = embeddings.shape[1]\n","\n","  word_index = tokenizer.word_index\n","  nb_words = min(10000, len(word_index))\n","\n","  embedding_matrix = np.random.normal(embedding_mean, embedding_std, (nb_words, embedding_size))\n","  for word, i in word_index.items():\n","      if i >= 10000:\n","          continue\n","      embedding_vector = embeddings_index.get(word)\n","      if embedding_vector is not None:\n","          embedding_matrix[i] = embedding_vector\n","  \n","  return embedding_matrix\n"],"metadata":{"id":"bx-T7hTBg6G0","executionInfo":{"status":"aborted","timestamp":1684711324372,"user_tz":-180,"elapsed":17,"user":{"displayName":"Alunat","userId":"04744058558773087828"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.layers import Bidirectional\n","\n","# LSTM\n","def construct_lstm(embedding_matrix):\n","  model = Sequential()\n","  model.add(Embedding(10000,\n","                      output_dim = 100,\n","                      weights = [embedding_matrix],\n","                      input_length = 300,\n","                      trainable = False))\n","\n","  model.add(LSTM(units = 128,\n","                return_sequences = True,\n","                recurrent_dropout = 0,\n","                dropout = 0.3,\n","                activation = \"tanh\",\n","                recurrent_activation = \"sigmoid\",\n","                  unroll=False,\n","                  use_bias = True\n","                  ))\n","\n","  model.add(LSTM(units = 64,\n","                recurrent_dropout = 0,\n","                dropout = 0.15,\n","                activation = \"tanh\",\n","                recurrent_activation = \"sigmoid\",\n","                unroll=False,\n","                use_bias = True))\n","\n","  model.add(Dense(units = 32,\n","                  activation = \"relu\"))\n","\n","  model.add(Dense(1,\n","                  activation = \"sigmoid\"))\n","\n","  model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001),\n","                loss = \"binary_crossentropy\",\n","                metrics = [\"accuracy\"])\n","\n","  return model\n","\n","# BiLSTM\n","def construct_bi_lstm(embedding_matrix):\n","  model = Sequential()\n","  model.add(Embedding(10000,\n","                      output_dim = 100,\n","                      weights = [embedding_matrix],\n","                      input_length = 300,\n","                      trainable = False))\n","   \n","  model.add(Bidirectional(LSTM(64, return_sequences = True,  recurrent_dropout=0, dropout = 0.15,\n","                activation = \"tanh\",\n","                recurrent_activation = \"sigmoid\",\n","                unroll=False,\n","                use_bias = True)))\n","  model.add(Bidirectional(LSTM(32,  recurrent_dropout=0)))\n","  model.add(Dense(units = 64, activation = \"relu\"))\n","  model.add(Dense(units = 1, activation = \"sigmoid\"))\n","  model.compile(optimizer = tf.keras.optimizers.Adam(learning_rate = 0.001),\n","              loss = \"binary_crossentropy\",\n","              metrics = [\"accuracy\"])\n","  \n","  return model"],"metadata":{"id":"JwIY6_2T8ceG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.models import Model\n","\n","\n","def get_selected_model(embedding_matrix, model_type='placeholder'):\n","  if model_type=='bi':\n","    return construct_bi_lstm(embedding_matrix)\n","  else:\n","    return construct_lstm(embedding_matrix)\n","\n","def train_dl_model(model, x_train, y_train, x_test, y_test):\n","  lr_reduce = ReduceLROnPlateau(monitor = \"val_loss\", patience = 5, factor = 0.5, min_lr = 0.00001)\n","\n","  history = model.fit(x_train,\n","                      y_train,\n","                      batch_size = 128,\n","                      validation_data = (x_test, y_test),\n","                      epochs = 10,\n","                      callbacks = [lr_reduce])\n","   \n","\n","def evaluate_dl_model(model, x_train, y_train, x_test, y_test):\n","   # Evaluation\n","  print(\"Model accuracy on training data - \" , model.evaluate(x_train, y_train)[1]*100 , \"%\")\n","  print(\"Model accuracy on testing data - \" , model.evaluate(x_test, y_test)[1]*100 , \"%\")\n","\n","  prediction = (model.predict(x_test) > 0.5).astype(\"int32\")\n","  print(classification_report(y_test, prediction, target_names = ['Fake','Real'], digits=3))\n","  tn, fp, fn, tp = confusion_matrix(y_test, prediction).ravel()\n","  specificity = tn / (tn+fp)\n","  print(f'Specificity {specificity}')\n","\n","def save_dl_model(model, filename):\n","  model.save(f'models/{filename}.h5')\n","  print(f'Model {filename} saved!')\n","\n","\n","\n","# types: 'bi' - bidirectional, \n","## can currently be a flag, but more types will be added in the future\n","def train_and_evalute_dl_model(dataset, attribute, model_type='placeholder', filename='dl_model' ):\n","  x_train, x_test, y_train, y_test = create_train_test_split(dataset, attribute)\n","  x_train, x_test, tokenizer = tokenize(x_train, x_test)\n","  embedding_matrix = generate_embedding_matrix(tokenizer)\n","  model = get_selected_model(embedding_matrix, model_type)\n","\n","  model.summary()\n","  train_dl_model(model, x_train, y_train, x_test, y_test)\n","  evaluate_dl_model(model, x_train, y_train, x_test, y_test)\n","  save_dl_model(model, filename)\n"],"metadata":{"id":"uNU4jV2C8yxo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gooWhKYe2fZl"},"source":["## Kaggle"]},{"cell_type":"markdown","metadata":{"id":"RLyBfUUP2fZm"},"source":["#### TFIDF + NB & Text"]},{"cell_type":"code","source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","vectorizer = TfidfVectorizer()\n","nb = MultinomialNB()\n","\n","train_and_eval_model(kaggle_data, 'cleaned_text', vectorizer, nb)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VgyrB38sHtWA","executionInfo":{"status":"ok","timestamp":1681417409067,"user_tz":-180,"elapsed":6667,"user":{"displayName":"Alunat","userId":"04744058558773087828"}},"outputId":"56c135ee-60d6-4967-ec2c-784ee3c1addd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.9273410180028494\n","              precision    recall  f1-score   support\n","\n","        True      0.895     0.983     0.937      4247\n","        Fake      0.977     0.859     0.914      3474\n","\n","    accuracy                          0.927      7721\n","   macro avg      0.936     0.921     0.926      7721\n","weighted avg      0.932     0.927     0.927      7721\n","\n","Specificity 0.9832823169295973\n"]}]},{"cell_type":"markdown","source":["#### TFIDF + NB & Title"],"metadata":{"id":"6BtTJp8ESXZz"}},{"cell_type":"code","source":["train_and_eval_model(kaggle_data, 'cleaned_title', vectorizer, nb)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"m8cFgohdYX2h","executionInfo":{"status":"ok","timestamp":1681419019643,"user_tz":-180,"elapsed":1151,"user":{"displayName":"Alunat","userId":"04744058558773087828"}},"outputId":"c8206be0-8ec3-4f3d-ee52-29856e9b8b4c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.932780727884989\n","              precision    recall  f1-score   support\n","\n","        True      0.933     0.945     0.939      4247\n","        Fake      0.932     0.918     0.925      3474\n","\n","    accuracy                          0.933      7721\n","   macro avg      0.933     0.931     0.932      7721\n","weighted avg      0.933     0.933     0.933      7721\n","\n","Specificity 0.9451377442900871\n"]}]},{"cell_type":"markdown","source":["#### TFIDF + NB & Combined\n","\n"],"metadata":{"id":"ktpSvQjjfE-z"}},{"cell_type":"code","source":["train_and_eval_model(kaggle_data, 'cleaned_combined', vectorizer, nb)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YcyQ3Smieo-Y","executionInfo":{"status":"ok","timestamp":1681420645221,"user_tz":-180,"elapsed":11276,"user":{"displayName":"Alunat","userId":"04744058558773087828"}},"outputId":"9d48507f-20b8-4952-da75-30597361ce42"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.9396451236886414\n","              precision    recall  f1-score   support\n","\n","        True      0.927     0.967     0.946      4247\n","        Fake      0.957     0.906     0.931      3474\n","\n","    accuracy                          0.940      7721\n","   macro avg      0.942     0.937     0.939      7721\n","weighted avg      0.940     0.940     0.939      7721\n","\n","Specificity 0.9668000941841299\n"]}]},{"cell_type":"markdown","source":["### **Logistic** Regression"],"metadata":{"id":"CabOu6VMMUMY"}},{"cell_type":"markdown","source":["#### TFIDF + LR & Text\n","\n"],"metadata":{"id":"eF9IE5yifdC0"}},{"cell_type":"code","source":["from sklearn.linear_model import LogisticRegression\n","\n","lr = LogisticRegression()\n","train_and_eval_model(kaggle_data, 'cleaned_text', vectorizer, lr)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LNy7_9z7MZ-5","executionInfo":{"status":"ok","timestamp":1681420903485,"user_tz":-180,"elapsed":11142,"user":{"displayName":"Alunat","userId":"04744058558773087828"}},"outputId":"ce2f40a2-6539-4e8f-d445-8dc7089e53a1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.9847170055692268\n","              precision    recall  f1-score   support\n","\n","        True      0.981     0.991     0.986      4247\n","        Fake      0.989     0.977     0.983      3474\n","\n","    accuracy                          0.985      7721\n","   macro avg      0.985     0.984     0.985      7721\n","weighted avg      0.985     0.985     0.985      7721\n","\n","Specificity 0.9910525076524606\n"]}]},{"cell_type":"markdown","source":["#### TFIDF + LR & Title"],"metadata":{"id":"3bBIOrJbfjye"}},{"cell_type":"code","source":["train_and_eval_model(kaggle_data, 'cleaned_title', vectorizer, lr)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YzgGUEY4foGo","executionInfo":{"status":"ok","timestamp":1681420921335,"user_tz":-180,"elapsed":1561,"user":{"displayName":"Alunat","userId":"04744058558773087828"}},"outputId":"8590d43b-6537-4f15-ef77-063390c1c628"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.9325216940810775\n","              precision    recall  f1-score   support\n","\n","        True      0.927     0.953     0.940      4247\n","        Fake      0.940     0.908     0.924      3474\n","\n","    accuracy                          0.933      7721\n","   macro avg      0.933     0.930     0.932      7721\n","weighted avg      0.933     0.933     0.932      7721\n","\n","Specificity 0.9526724746880151\n"]}]},{"cell_type":"markdown","source":["#### TFIDF + LR & Combined"],"metadata":{"id":"p_TMRM9afl9A"}},{"cell_type":"code","source":["train_and_eval_model(kaggle_data, 'cleaned_combined', vectorizer, lr)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pRzlFjY0MTmy","executionInfo":{"status":"ok","timestamp":1681420960427,"user_tz":-180,"elapsed":13543,"user":{"displayName":"Alunat","userId":"04744058558773087828"}},"outputId":"b73d9b1f-c91a-4467-e854-b6c3d09097cf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.984198937961404\n","              precision    recall  f1-score   support\n","\n","        True      0.980     0.992     0.986      4247\n","        Fake      0.990     0.975     0.982      3474\n","\n","    accuracy                          0.984      7721\n","   macro avg      0.985     0.983     0.984      7721\n","weighted avg      0.984     0.984     0.984      7721\n","\n","Specificity 0.9919943489522015\n"]}]},{"cell_type":"markdown","source":["\n","\n","---\n","\n"],"metadata":{"id":"CMYURupSMXzr"}},{"cell_type":"markdown","metadata":{"id":"nj4Zr87F2fZo"},"source":["#### Glove + LSTM & Text"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zThIX2oD2fZo","outputId":"61132d45-6a17-4adf-ed6b-96e5944013b9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683398520249,"user_tz":-180,"elapsed":194914,"user":{"displayName":"Alunat","userId":"04744058558773087828"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-19-1bbc3a5794c0>:2: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n","  train_and_evalute_dl_model(kaggle_data, 'cleaned_text', seq, filename=\"kaggle_lstm_text\")\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"sequential_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding (Embedding)       (None, 300, 100)          1000000   \n","                                                                 \n"," lstm (LSTM)                 (None, 300, 128)          117248    \n","                                                                 \n"," lstm_1 (LSTM)               (None, 64)                49408     \n","                                                                 \n"," dense (Dense)               (None, 32)                2080      \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 1,168,769\n","Trainable params: 168,769\n","Non-trainable params: 1,000,000\n","_________________________________________________________________\n","Epoch 1/10\n","242/242 [==============================] - 18s 39ms/step - loss: 0.2470 - accuracy: 0.9031 - val_loss: 0.1235 - val_accuracy: 0.9529 - lr: 0.0010\n","Epoch 2/10\n","242/242 [==============================] - 9s 36ms/step - loss: 0.2138 - accuracy: 0.9178 - val_loss: 0.1411 - val_accuracy: 0.9500 - lr: 0.0010\n","Epoch 3/10\n","242/242 [==============================] - 9s 36ms/step - loss: 0.1082 - accuracy: 0.9607 - val_loss: 0.1143 - val_accuracy: 0.9532 - lr: 0.0010\n","Epoch 4/10\n","242/242 [==============================] - 9s 36ms/step - loss: 0.0840 - accuracy: 0.9700 - val_loss: 0.0505 - val_accuracy: 0.9836 - lr: 0.0010\n","Epoch 5/10\n","242/242 [==============================] - 9s 36ms/step - loss: 0.0606 - accuracy: 0.9793 - val_loss: 0.0367 - val_accuracy: 0.9885 - lr: 0.0010\n","Epoch 6/10\n","242/242 [==============================] - 9s 36ms/step - loss: 0.0403 - accuracy: 0.9867 - val_loss: 0.0380 - val_accuracy: 0.9886 - lr: 0.0010\n","Epoch 7/10\n","242/242 [==============================] - 9s 36ms/step - loss: 0.0336 - accuracy: 0.9890 - val_loss: 0.0310 - val_accuracy: 0.9894 - lr: 0.0010\n","Epoch 8/10\n","242/242 [==============================] - 9s 36ms/step - loss: 0.0324 - accuracy: 0.9895 - val_loss: 0.0324 - val_accuracy: 0.9891 - lr: 0.0010\n","Epoch 9/10\n","242/242 [==============================] - 9s 36ms/step - loss: 0.0235 - accuracy: 0.9919 - val_loss: 0.0242 - val_accuracy: 0.9927 - lr: 0.0010\n","Epoch 10/10\n","242/242 [==============================] - 9s 36ms/step - loss: 0.0215 - accuracy: 0.9931 - val_loss: 0.0265 - val_accuracy: 0.9922 - lr: 0.0010\n","966/966 [==============================] - 9s 9ms/step - loss: 0.0168 - accuracy: 0.9948\n","Model accuracy on training data -  99.4819164276123 %\n","242/242 [==============================] - 2s 9ms/step - loss: 0.0265 - accuracy: 0.9922\n","Model accuracy on testing data -  99.22289848327637 %\n","242/242 [==============================] - 3s 8ms/step\n","              precision    recall  f1-score   support\n","\n","        Fake      0.990     0.996     0.993      4247\n","        Real      0.995     0.987     0.991      3474\n","\n","    accuracy                          0.992      7721\n","   macro avg      0.993     0.992     0.992      7721\n","weighted avg      0.992     0.992     0.992      7721\n","\n","Specificity 0.9962326348010361\n","Model kaggle_lstm_text saved!\n"]}],"source":["seq = Sequential()\n","train_and_evalute_dl_model(kaggle_data, 'cleaned_text', seq, filename=\"kaggle_lstm_text\")"]},{"cell_type":"markdown","metadata":{"id":"5dktvtLy2fZp"},"source":["#### Glove + LSTM & Title"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i6Kn38MB2fZq","outputId":"7b090b27-6ba3-424d-f343-d0ff93ca73da","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1681432659250,"user_tz":-180,"elapsed":130638,"user":{"displayName":"Alunat","userId":"04744058558773087828"}}},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-37-080d608a1352>:2: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n","  train_and_evalute_dl_model(kaggle_data, 'cleaned_title', seq)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","242/242 [==============================] - 13s 39ms/step - loss: 0.3270 - accuracy: 0.8558 - val_loss: 0.2502 - val_accuracy: 0.8966 - lr: 0.0010\n","Epoch 2/10\n","242/242 [==============================] - 9s 36ms/step - loss: 0.2329 - accuracy: 0.9030 - val_loss: 0.2030 - val_accuracy: 0.9170 - lr: 0.0010\n","Epoch 3/10\n","242/242 [==============================] - 9s 37ms/step - loss: 0.2031 - accuracy: 0.9174 - val_loss: 0.1803 - val_accuracy: 0.9270 - lr: 0.0010\n","Epoch 4/10\n","242/242 [==============================] - 9s 36ms/step - loss: 0.1829 - accuracy: 0.9242 - val_loss: 0.1677 - val_accuracy: 0.9317 - lr: 0.0010\n","Epoch 5/10\n","242/242 [==============================] - 9s 36ms/step - loss: 0.1704 - accuracy: 0.9300 - val_loss: 0.1767 - val_accuracy: 0.9276 - lr: 0.0010\n","Epoch 6/10\n","242/242 [==============================] - 9s 36ms/step - loss: 0.1581 - accuracy: 0.9366 - val_loss: 0.1549 - val_accuracy: 0.9400 - lr: 0.0010\n","Epoch 7/10\n","242/242 [==============================] - 9s 36ms/step - loss: 0.1462 - accuracy: 0.9402 - val_loss: 0.1610 - val_accuracy: 0.9400 - lr: 0.0010\n","Epoch 8/10\n","242/242 [==============================] - 9s 36ms/step - loss: 0.1394 - accuracy: 0.9444 - val_loss: 0.2134 - val_accuracy: 0.9171 - lr: 0.0010\n","Epoch 9/10\n","242/242 [==============================] - 9s 36ms/step - loss: 0.1324 - accuracy: 0.9472 - val_loss: 0.1479 - val_accuracy: 0.9442 - lr: 0.0010\n","Epoch 10/10\n","242/242 [==============================] - 9s 36ms/step - loss: 0.1271 - accuracy: 0.9498 - val_loss: 0.1633 - val_accuracy: 0.9398 - lr: 0.0010\n","966/966 [==============================] - 9s 9ms/step - loss: 0.0895 - accuracy: 0.9664\n","Model accuracy on training data -  96.63892984390259 %\n","242/242 [==============================] - 2s 9ms/step - loss: 0.1633 - accuracy: 0.9398\n","Model accuracy on testing data -  93.97746324539185 %\n","242/242 [==============================] - 2s 8ms/step\n","              precision    recall  f1-score   support\n","\n","        Fake      0.922     0.973     0.947      4247\n","        Real      0.965     0.899     0.931      3474\n","\n","    accuracy                          0.940      7721\n","   macro avg      0.943     0.936     0.939      7721\n","weighted avg      0.941     0.940     0.940      7721\n","\n"]}],"source":["seq = Sequential()\n","train_and_evalute_dl_model(kaggle_data, 'cleaned_title', seq)"]},{"cell_type":"markdown","source":["#### Glove + LSTM & Combined"],"metadata":{"id":"SbD972z8M-9p"}},{"cell_type":"code","source":["seq = Sequential()\n","train_and_evalute_dl_model(kaggle_data, 'cleaned_combined', seq)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tb18c9z7M9fz","executionInfo":{"status":"ok","timestamp":1681432946162,"user_tz":-180,"elapsed":155104,"user":{"displayName":"Alunat","userId":"04744058558773087828"}},"outputId":"007bae33-79e2-4bb4-f670-704ca3e16df4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-39-d727d62dfa25>:2: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n","  train_and_evalute_dl_model(kaggle_data, 'cleaned_combined', seq)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","242/242 [==============================] - 13s 39ms/step - loss: 0.2589 - accuracy: 0.8973 - val_loss: 0.1906 - val_accuracy: 0.9282 - lr: 0.0010\n","Epoch 2/10\n","242/242 [==============================] - 9s 36ms/step - loss: 0.1843 - accuracy: 0.9316 - val_loss: 0.1847 - val_accuracy: 0.9346 - lr: 0.0010\n","Epoch 3/10\n","242/242 [==============================] - 9s 37ms/step - loss: 0.1733 - accuracy: 0.9324 - val_loss: 0.2055 - val_accuracy: 0.9272 - lr: 0.0010\n","Epoch 4/10\n","242/242 [==============================] - 9s 37ms/step - loss: 0.1367 - accuracy: 0.9500 - val_loss: 0.1002 - val_accuracy: 0.9678 - lr: 0.0010\n","Epoch 5/10\n","242/242 [==============================] - 9s 36ms/step - loss: 0.1016 - accuracy: 0.9662 - val_loss: 0.1114 - val_accuracy: 0.9637 - lr: 0.0010\n","Epoch 6/10\n","242/242 [==============================] - 9s 36ms/step - loss: 0.1012 - accuracy: 0.9659 - val_loss: 0.0619 - val_accuracy: 0.9784 - lr: 0.0010\n","Epoch 7/10\n","242/242 [==============================] - 9s 36ms/step - loss: 0.0688 - accuracy: 0.9765 - val_loss: 0.0779 - val_accuracy: 0.9711 - lr: 0.0010\n","Epoch 8/10\n","242/242 [==============================] - 9s 36ms/step - loss: 0.0776 - accuracy: 0.9735 - val_loss: 0.0556 - val_accuracy: 0.9819 - lr: 0.0010\n","Epoch 9/10\n","242/242 [==============================] - 9s 36ms/step - loss: 0.0710 - accuracy: 0.9770 - val_loss: 0.0582 - val_accuracy: 0.9806 - lr: 0.0010\n","Epoch 10/10\n","242/242 [==============================] - 9s 36ms/step - loss: 0.0612 - accuracy: 0.9790 - val_loss: 0.0432 - val_accuracy: 0.9858 - lr: 0.0010\n","966/966 [==============================] - 9s 9ms/step - loss: 0.0373 - accuracy: 0.9884\n","Model accuracy on training data -  98.8407850265503 %\n","242/242 [==============================] - 2s 9ms/step - loss: 0.0432 - accuracy: 0.9858\n","Model accuracy on testing data -  98.57531189918518 %\n","242/242 [==============================] - 3s 8ms/step\n","              precision    recall  f1-score   support\n","\n","        Fake      0.981     0.994     0.987      4247\n","        Real      0.992     0.976     0.984      3474\n","\n","    accuracy                          0.986      7721\n","   macro avg      0.986     0.985     0.986      7721\n","weighted avg      0.986     0.986     0.986      7721\n","\n"]}]},{"cell_type":"markdown","source":["#### Glove + BiLSTM & Text"],"metadata":{"id":"nhaa_1qGO8xR"}},{"cell_type":"code","source":["train_and_evalute_dl_model(kaggle_data, 'cleaned_text', model_type='bi')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":165},"id":"Wm-EGeBRO3ai","executionInfo":{"status":"error","timestamp":1683381657468,"user_tz":-180,"elapsed":15,"user":{"displayName":"Alunat","userId":"04744058558773087828"}},"outputId":"ef9f75f2-d305-4e25-dbaf-1f77e4c3e362"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-e884a1107d32>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_and_evalute_dl_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkaggle_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cleaned_text'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bi'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'train_and_evalute_dl_model' is not defined"]}]},{"cell_type":"markdown","source":["#### Glove + BiLSTM & Title"],"metadata":{"id":"-NCndplWPJ3d"}},{"cell_type":"code","source":["seq = Sequential()\n","train_and_evalute_dl_model(kaggle_data, 'cleaned_title', model_type='bi')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W0XJc-XmPUi0","executionInfo":{"status":"ok","timestamp":1681440718175,"user_tz":-180,"elapsed":172507,"user":{"displayName":"Alunat","userId":"04744058558773087828"}},"outputId":"97b7d45c-1824-46d8-d9f5-bd836402b5e6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-102-9b78ff0ef1dd>:2: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n","  train_and_evalute_dl_model(kaggle_data, 'cleaned_title', model_type='bi')\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"sequential_36\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_28 (Embedding)    (None, 300, 100)          1000000   \n","                                                                 \n"," bidirectional_26 (Bidirecti  (None, 300, 128)         84480     \n"," onal)                                                           \n","                                                                 \n"," bidirectional_27 (Bidirecti  (None, 64)               41216     \n"," onal)                                                           \n","                                                                 \n"," dense_52 (Dense)            (None, 64)                4160      \n","                                                                 \n"," dense_53 (Dense)            (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 1,129,921\n","Trainable params: 129,921\n","Non-trainable params: 1,000,000\n","_________________________________________________________________\n","Epoch 1/10\n","242/242 [==============================] - 20s 54ms/step - loss: 0.2968 - accuracy: 0.8710 - val_loss: 0.2189 - val_accuracy: 0.9114 - lr: 0.0010\n","Epoch 2/10\n","242/242 [==============================] - 12s 48ms/step - loss: 0.1996 - accuracy: 0.9185 - val_loss: 0.1942 - val_accuracy: 0.9241 - lr: 0.0010\n","Epoch 3/10\n","242/242 [==============================] - 11s 47ms/step - loss: 0.1712 - accuracy: 0.9316 - val_loss: 0.1998 - val_accuracy: 0.9205 - lr: 0.0010\n","Epoch 4/10\n","242/242 [==============================] - 11s 47ms/step - loss: 0.1540 - accuracy: 0.9386 - val_loss: 0.1679 - val_accuracy: 0.9363 - lr: 0.0010\n","Epoch 5/10\n","242/242 [==============================] - 11s 47ms/step - loss: 0.1331 - accuracy: 0.9470 - val_loss: 0.1613 - val_accuracy: 0.9394 - lr: 0.0010\n","Epoch 6/10\n","242/242 [==============================] - 11s 47ms/step - loss: 0.1200 - accuracy: 0.9538 - val_loss: 0.1438 - val_accuracy: 0.9459 - lr: 0.0010\n","Epoch 7/10\n","242/242 [==============================] - 11s 47ms/step - loss: 0.1104 - accuracy: 0.9561 - val_loss: 0.1445 - val_accuracy: 0.9433 - lr: 0.0010\n","Epoch 8/10\n","242/242 [==============================] - 11s 47ms/step - loss: 0.1005 - accuracy: 0.9609 - val_loss: 0.1626 - val_accuracy: 0.9407 - lr: 0.0010\n","Epoch 9/10\n","242/242 [==============================] - 11s 47ms/step - loss: 0.0923 - accuracy: 0.9638 - val_loss: 0.1509 - val_accuracy: 0.9453 - lr: 0.0010\n","Epoch 10/10\n","242/242 [==============================] - 11s 47ms/step - loss: 0.0835 - accuracy: 0.9677 - val_loss: 0.1587 - val_accuracy: 0.9452 - lr: 0.0010\n","966/966 [==============================] - 14s 15ms/step - loss: 0.0509 - accuracy: 0.9824\n","Model accuracy on training data -  98.23851585388184 %\n","242/242 [==============================] - 4s 16ms/step - loss: 0.1587 - accuracy: 0.9452\n","Model accuracy on testing data -  94.5214331150055 %\n","242/242 [==============================] - 5s 14ms/step\n","              precision    recall  f1-score   support\n","\n","        Fake      0.954     0.946     0.950      4247\n","        Real      0.935     0.944     0.939      3474\n","\n","    accuracy                          0.945      7721\n","   macro avg      0.944     0.945     0.945      7721\n","weighted avg      0.945     0.945     0.945      7721\n","\n","Specificity 0.9463150459147633\n"]}]},{"cell_type":"markdown","source":["#### Glove + BiLSTM & Combined"],"metadata":{"id":"zA-kCQfDPJpT"}},{"cell_type":"code","source":["seq = Sequential()\n","train_and_evalute_dl_model(kaggle_data, 'cleaned_combined', seq, model_type='bi')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GlPbvRn1PVXn","executionInfo":{"status":"ok","timestamp":1681434815498,"user_tz":-180,"elapsed":194380,"user":{"displayName":"Alunat","userId":"04744058558773087828"}},"outputId":"799bbdb8-2450-4c4e-d101-a17f19446c42"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-54-64b5cf3f8fff>:2: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n","  train_and_evalute_dl_model(kaggle_data, 'cleaned_combined', seq, model_type='bi')\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10\n","242/242 [==============================] - 18s 51ms/step - loss: 0.1877 - accuracy: 0.9292 - val_loss: 0.1069 - val_accuracy: 0.9631 - lr: 0.0010\n","Epoch 2/10\n","242/242 [==============================] - 11s 47ms/step - loss: 0.1227 - accuracy: 0.9564 - val_loss: 0.0805 - val_accuracy: 0.9728 - lr: 0.0010\n","Epoch 3/10\n","242/242 [==============================] - 11s 46ms/step - loss: 0.0848 - accuracy: 0.9713 - val_loss: 0.1477 - val_accuracy: 0.9509 - lr: 0.0010\n","Epoch 4/10\n","242/242 [==============================] - 11s 46ms/step - loss: 0.0700 - accuracy: 0.9775 - val_loss: 0.0542 - val_accuracy: 0.9815 - lr: 0.0010\n","Epoch 5/10\n","242/242 [==============================] - 11s 45ms/step - loss: 0.0520 - accuracy: 0.9825 - val_loss: 0.0437 - val_accuracy: 0.9839 - lr: 0.0010\n","Epoch 6/10\n","242/242 [==============================] - 11s 45ms/step - loss: 0.0404 - accuracy: 0.9865 - val_loss: 0.0441 - val_accuracy: 0.9837 - lr: 0.0010\n","Epoch 7/10\n","242/242 [==============================] - 11s 45ms/step - loss: 0.0291 - accuracy: 0.9901 - val_loss: 0.0271 - val_accuracy: 0.9920 - lr: 0.0010\n","Epoch 8/10\n","242/242 [==============================] - 11s 46ms/step - loss: 0.0226 - accuracy: 0.9926 - val_loss: 0.0297 - val_accuracy: 0.9907 - lr: 0.0010\n","Epoch 9/10\n","242/242 [==============================] - 11s 46ms/step - loss: 0.0191 - accuracy: 0.9937 - val_loss: 0.0307 - val_accuracy: 0.9898 - lr: 0.0010\n","Epoch 10/10\n","242/242 [==============================] - 11s 46ms/step - loss: 0.0189 - accuracy: 0.9936 - val_loss: 0.0280 - val_accuracy: 0.9915 - lr: 0.0010\n","966/966 [==============================] - 14s 15ms/step - loss: 0.0138 - accuracy: 0.9955\n","Model accuracy on training data -  99.55314993858337 %\n","242/242 [==============================] - 4s 15ms/step - loss: 0.0280 - accuracy: 0.9915\n","Model accuracy on testing data -  99.14518594741821 %\n","242/242 [==============================] - 5s 15ms/step\n","              precision    recall  f1-score   support\n","\n","        Fake      0.988     0.996     0.992      4247\n","        Real      0.996     0.985     0.990      3474\n","\n","    accuracy                          0.991      7721\n","   macro avg      0.992     0.991     0.991      7721\n","weighted avg      0.991     0.991     0.991      7721\n","\n","Specificity 0.9964680951259712\n"]}]},{"cell_type":"markdown","metadata":{"id":"uqXXi9Qs2fZs"},"source":["# Wellfake **"]},{"cell_type":"markdown","source":["### Logistic Regression"],"metadata":{"id":"nQeXbKJBVgVa"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZKpUS-XM2fZs","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683849650774,"user_tz":-180,"elapsed":19001,"user":{"displayName":"Alunat","userId":"04744058558773087828"}},"outputId":"56946c10-b04b-4450-efd5-372aeb243c2f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.9380294248773964\n","              precision    recall  f1-score   support\n","\n","        True      0.946     0.940     0.943      4868\n","        Fake      0.929     0.936     0.933      4104\n","\n","    accuracy                          0.938      8972\n","   macro avg      0.937     0.938     0.938      8972\n","weighted avg      0.938     0.938     0.938      8972\n","\n","Specificity 0.9398110106820049\n","Model classical_model saved!\n"]}],"source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","vectorizer = TfidfVectorizer()\n","\n","lr = LogisticRegression()\n","train_and_eval_model(wellfake_data, 'cleaned_text', vectorizer, lr)"]},{"cell_type":"code","source":["train_and_eval_model(wellfake_data, 'cleaned_title', vectorizer, lr, filename=\"wellfake_lr_title\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q3VT71kkVm50","executionInfo":{"status":"ok","timestamp":1683851629419,"user_tz":-180,"elapsed":1034,"user":{"displayName":"Alunat","userId":"04744058558773087828"}},"outputId":"7ec48dfc-0915-4abd-c0ed-5cc65cc04c2c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.8808515381185912\n","              precision    recall  f1-score   support\n","\n","        True      0.896     0.882     0.889      4868\n","        Fake      0.863     0.879     0.871      4104\n","\n","    accuracy                          0.881      8972\n","   macro avg      0.880     0.881     0.880      8972\n","weighted avg      0.881     0.881     0.881      8972\n","\n","Specificity 0.8824979457682827\n","Model wellfake_lr_title saved!\n"]}]},{"cell_type":"code","source":["train_and_eval_model(wellfake_data, 'cleaned_combined', vectorizer, lr, filename=\"wellfake_lr_combined\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pg8zoDK2VqVL","executionInfo":{"status":"ok","timestamp":1683401229991,"user_tz":-180,"elapsed":31303,"user":{"displayName":"Alunat","userId":"04744058558773087828"}},"outputId":"3c6fe3c8-ce89-4e71-e99b-becd9f1787c8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.9478377173428444\n","              precision    recall  f1-score   support\n","\n","        True      0.951     0.953     0.952      4868\n","        Fake      0.944     0.942     0.943      4104\n","\n","    accuracy                          0.948      8972\n","   macro avg      0.948     0.947     0.947      8972\n","weighted avg      0.948     0.948     0.948      8972\n","\n","Specificity 0.9529580936729664\n"]}]},{"cell_type":"markdown","source":["### Naive Bayes"],"metadata":{"id":"KQ3iR55CWbMW"}},{"cell_type":"code","source":["nb = MultinomialNB()\n","\n","train_and_eval_model(wellfake_data, 'cleaned_text', vectorizer, nb)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4fYcRuBPWdqJ","executionInfo":{"status":"ok","timestamp":1681435440729,"user_tz":-180,"elapsed":11786,"user":{"displayName":"Alunat","userId":"04744058558773087828"}},"outputId":"dcbdef71-b454-4bb6-ebc2-b1693f7b6da3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.765492643780651\n","              precision    recall  f1-score   support\n","\n","        True      0.700     0.992     0.821      4868\n","        Fake      0.981     0.497     0.660      4104\n","\n","    accuracy                          0.765      8972\n","   macro avg      0.841     0.744     0.740      8972\n","weighted avg      0.829     0.765     0.747      8972\n","\n","Specificity 0.991988496302383\n"]}]},{"cell_type":"code","source":["train_and_eval_model(wellfake_data, 'cleaned_title', vectorizer, nb)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1otYd-y8W_6J","executionInfo":{"status":"ok","timestamp":1681435440731,"user_tz":-180,"elapsed":9,"user":{"displayName":"Alunat","userId":"04744058558773087828"}},"outputId":"e539c62c-f120-48a5-c2e9-48855cc7c8f8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.8533214444939813\n","              precision    recall  f1-score   support\n","\n","        True      0.827     0.922     0.872      4868\n","        Fake      0.893     0.772     0.828      4104\n","\n","    accuracy                          0.853      8972\n","   macro avg      0.860     0.847     0.850      8972\n","weighted avg      0.857     0.853     0.852      8972\n","\n","Specificity 0.9221446179129006\n"]}]},{"cell_type":"code","source":["train_and_eval_model(wellfake_data, 'cleaned_combined', vectorizer, nb)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WgCfZMN_XARc","executionInfo":{"status":"ok","timestamp":1681435458382,"user_tz":-180,"elapsed":17656,"user":{"displayName":"Alunat","userId":"04744058558773087828"}},"outputId":"b5280a60-c033-4a86-d1ec-6a8ea724b3e8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Accuracy: 0.8174320106999554\n","              precision    recall  f1-score   support\n","\n","        True      0.755     0.981     0.854      4868\n","        Fake      0.965     0.623     0.757      4104\n","\n","    accuracy                          0.817      8972\n","   macro avg      0.860     0.802     0.806      8972\n","weighted avg      0.851     0.817     0.810      8972\n","\n","Specificity 0.981101068200493\n"]}]},{"cell_type":"markdown","metadata":{"id":"v5Nxx5yh2fZt"},"source":["#### Glove & LSTM"]},{"cell_type":"markdown","metadata":{"id":"ikhmmNc32fZu"},"source":["##### LSTM"]},{"cell_type":"code","source":["train_and_evalute_dl_model(wellfake_data, 'cleaned_text')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jV-2Ikbw-ok4","executionInfo":{"status":"ok","timestamp":1681437751470,"user_tz":-180,"elapsed":159108,"user":{"displayName":"Alunat","userId":"04744058558773087828"}},"outputId":"21192443-251b-4eb3-e1ba-e089177a9f23"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-84-70d6bd1b63be>:1: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n","  train_and_evalute_dl_model(wellfake_data, 'cleaned_text')\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"sequential_23\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_18 (Embedding)    (None, 300, 100)          1000000   \n","                                                                 \n"," lstm_34 (LSTM)              (None, 300, 128)          117248    \n","                                                                 \n"," lstm_35 (LSTM)              (None, 64)                49408     \n","                                                                 \n"," dense_34 (Dense)            (None, 32)                2080      \n","                                                                 \n"," dense_35 (Dense)            (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 1,168,769\n","Trainable params: 168,769\n","Non-trainable params: 1,000,000\n","_________________________________________________________________\n","Epoch 1/10\n","281/281 [==============================] - 15s 38ms/step - loss: 0.4501 - accuracy: 0.7850 - val_loss: 0.3992 - val_accuracy: 0.8006 - lr: 0.0010\n","Epoch 2/10\n","281/281 [==============================] - 10s 36ms/step - loss: 0.3851 - accuracy: 0.8229 - val_loss: 0.3012 - val_accuracy: 0.8693 - lr: 0.0010\n","Epoch 3/10\n","281/281 [==============================] - 10s 36ms/step - loss: 0.2850 - accuracy: 0.8786 - val_loss: 0.2322 - val_accuracy: 0.9038 - lr: 0.0010\n","Epoch 4/10\n","281/281 [==============================] - 10s 36ms/step - loss: 0.2312 - accuracy: 0.9012 - val_loss: 0.2033 - val_accuracy: 0.9136 - lr: 0.0010\n","Epoch 5/10\n","281/281 [==============================] - 10s 36ms/step - loss: 0.2043 - accuracy: 0.9129 - val_loss: 0.1975 - val_accuracy: 0.9176 - lr: 0.0010\n","Epoch 6/10\n","281/281 [==============================] - 10s 36ms/step - loss: 0.1916 - accuracy: 0.9204 - val_loss: 0.1683 - val_accuracy: 0.9310 - lr: 0.0010\n","Epoch 7/10\n","281/281 [==============================] - 10s 36ms/step - loss: 0.1755 - accuracy: 0.9274 - val_loss: 0.1675 - val_accuracy: 0.9298 - lr: 0.0010\n","Epoch 8/10\n","281/281 [==============================] - 10s 36ms/step - loss: 0.1699 - accuracy: 0.9287 - val_loss: 0.1604 - val_accuracy: 0.9355 - lr: 0.0010\n","Epoch 9/10\n","281/281 [==============================] - 10s 36ms/step - loss: 0.1578 - accuracy: 0.9345 - val_loss: 0.1470 - val_accuracy: 0.9430 - lr: 0.0010\n","Epoch 10/10\n","281/281 [==============================] - 10s 36ms/step - loss: 0.1487 - accuracy: 0.9397 - val_loss: 0.1453 - val_accuracy: 0.9405 - lr: 0.0010\n","1122/1122 [==============================] - 10s 9ms/step - loss: 0.1156 - accuracy: 0.9520\n","Model accuracy on training data -  95.2014684677124 %\n","281/281 [==============================] - 3s 9ms/step - loss: 0.1453 - accuracy: 0.9405\n","Model accuracy on testing data -  94.04814839363098 %\n","281/281 [==============================] - 3s 8ms/step\n","              precision    recall  f1-score   support\n","\n","        Fake      0.946     0.945     0.945      4868\n","        Real      0.935     0.935     0.935      4104\n","\n","    accuracy                          0.940      8972\n","   macro avg      0.940     0.940     0.940      8972\n","weighted avg      0.940     0.940     0.940      8972\n","\n","Specificity 0.9447411668036154\n"]}]},{"cell_type":"code","source":["train_and_evalute_dl_model(wellfake_data, 'cleaned_title')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rbHYyezFX9I7","executionInfo":{"status":"ok","timestamp":1681438060068,"user_tz":-180,"elapsed":185363,"user":{"displayName":"Alunat","userId":"04744058558773087828"}},"outputId":"92cb954d-e5ed-404a-fddb-b3550259d120"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-87-699a45f5eee1>:1: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n","  train_and_evalute_dl_model(wellfake_data, 'cleaned_title')\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"sequential_26\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_20 (Embedding)    (None, 300, 100)          1000000   \n","                                                                 \n"," lstm_38 (LSTM)              (None, 300, 128)          117248    \n","                                                                 \n"," lstm_39 (LSTM)              (None, 64)                49408     \n","                                                                 \n"," dense_38 (Dense)            (None, 32)                2080      \n","                                                                 \n"," dense_39 (Dense)            (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 1,168,769\n","Trainable params: 168,769\n","Non-trainable params: 1,000,000\n","_________________________________________________________________\n","Epoch 1/10\n","281/281 [==============================] - 14s 38ms/step - loss: 0.4137 - accuracy: 0.8000 - val_loss: 0.3376 - val_accuracy: 0.8428 - lr: 0.0010\n","Epoch 2/10\n","281/281 [==============================] - 10s 36ms/step - loss: 0.3338 - accuracy: 0.8458 - val_loss: 0.3110 - val_accuracy: 0.8590 - lr: 0.0010\n","Epoch 3/10\n","281/281 [==============================] - 10s 36ms/step - loss: 0.3096 - accuracy: 0.8592 - val_loss: 0.3021 - val_accuracy: 0.8615 - lr: 0.0010\n","Epoch 4/10\n","281/281 [==============================] - 10s 36ms/step - loss: 0.2931 - accuracy: 0.8691 - val_loss: 0.2830 - val_accuracy: 0.8707 - lr: 0.0010\n","Epoch 5/10\n","281/281 [==============================] - 10s 36ms/step - loss: 0.2777 - accuracy: 0.8764 - val_loss: 0.2720 - val_accuracy: 0.8770 - lr: 0.0010\n","Epoch 6/10\n","281/281 [==============================] - 10s 36ms/step - loss: 0.2673 - accuracy: 0.8825 - val_loss: 0.3085 - val_accuracy: 0.8665 - lr: 0.0010\n","Epoch 7/10\n","281/281 [==============================] - 10s 35ms/step - loss: 0.2562 - accuracy: 0.8883 - val_loss: 0.2636 - val_accuracy: 0.8817 - lr: 0.0010\n","Epoch 8/10\n","281/281 [==============================] - 10s 35ms/step - loss: 0.2485 - accuracy: 0.8892 - val_loss: 0.2725 - val_accuracy: 0.8820 - lr: 0.0010\n","Epoch 9/10\n","281/281 [==============================] - 10s 35ms/step - loss: 0.2355 - accuracy: 0.8987 - val_loss: 0.2660 - val_accuracy: 0.8810 - lr: 0.0010\n","Epoch 10/10\n","281/281 [==============================] - 10s 36ms/step - loss: 0.2280 - accuracy: 0.9013 - val_loss: 0.2613 - val_accuracy: 0.8870 - lr: 0.0010\n","1122/1122 [==============================] - 10s 9ms/step - loss: 0.1794 - accuracy: 0.9236\n","Model accuracy on training data -  92.35913753509521 %\n","281/281 [==============================] - 2s 9ms/step - loss: 0.2613 - accuracy: 0.8870\n","Model accuracy on testing data -  88.6981725692749 %\n","281/281 [==============================] - 3s 8ms/step\n","              precision    recall  f1-score   support\n","\n","        Fake      0.902     0.888     0.895      4868\n","        Real      0.870     0.885     0.878      4104\n","\n","    accuracy                          0.887      8972\n","   macro avg      0.886     0.887     0.886      8972\n","weighted avg      0.887     0.887     0.887      8972\n","\n","Specificity 0.8882497945768283\n"]}]},{"cell_type":"code","source":["train_and_evalute_dl_model(wellfake_data, 'cleaned_combined', 'wellfake_lstm_combined')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UCTVwYTyX_-j","executionInfo":{"status":"ok","timestamp":1683399390523,"user_tz":-180,"elapsed":208069,"user":{"displayName":"Alunat","userId":"04744058558773087828"}},"outputId":"2635ec71-804c-4a72-f6ab-8dfc8b25513a"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_4\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_2 (Embedding)     (None, 300, 100)          1000000   \n","                                                                 \n"," lstm_4 (LSTM)               (None, 300, 128)          117248    \n","                                                                 \n"," lstm_5 (LSTM)               (None, 64)                49408     \n","                                                                 \n"," dense_4 (Dense)             (None, 32)                2080      \n","                                                                 \n"," dense_5 (Dense)             (None, 1)                 33        \n","                                                                 \n","=================================================================\n","Total params: 1,168,769\n","Trainable params: 168,769\n","Non-trainable params: 1,000,000\n","_________________________________________________________________\n","Epoch 1/10\n","281/281 [==============================] - 14s 38ms/step - loss: 0.4244 - accuracy: 0.8011 - val_loss: 0.3283 - val_accuracy: 0.8576 - lr: 0.0010\n","Epoch 2/10\n","281/281 [==============================] - 10s 36ms/step - loss: 0.3916 - accuracy: 0.8208 - val_loss: 0.4308 - val_accuracy: 0.7893 - lr: 0.0010\n","Epoch 3/10\n","281/281 [==============================] - 10s 36ms/step - loss: 0.3536 - accuracy: 0.8430 - val_loss: 0.3020 - val_accuracy: 0.8562 - lr: 0.0010\n","Epoch 4/10\n","281/281 [==============================] - 10s 36ms/step - loss: 0.2546 - accuracy: 0.8949 - val_loss: 0.1964 - val_accuracy: 0.9233 - lr: 0.0010\n","Epoch 5/10\n","281/281 [==============================] - 10s 37ms/step - loss: 0.1978 - accuracy: 0.9187 - val_loss: 0.1881 - val_accuracy: 0.9203 - lr: 0.0010\n","Epoch 6/10\n","281/281 [==============================] - 10s 36ms/step - loss: 0.1755 - accuracy: 0.9275 - val_loss: 0.1547 - val_accuracy: 0.9381 - lr: 0.0010\n","Epoch 7/10\n","281/281 [==============================] - 10s 36ms/step - loss: 0.1604 - accuracy: 0.9358 - val_loss: 0.1400 - val_accuracy: 0.9455 - lr: 0.0010\n","Epoch 8/10\n","281/281 [==============================] - 10s 36ms/step - loss: 0.1460 - accuracy: 0.9399 - val_loss: 0.1661 - val_accuracy: 0.9299 - lr: 0.0010\n","Epoch 9/10\n","281/281 [==============================] - 10s 36ms/step - loss: 0.1390 - accuracy: 0.9430 - val_loss: 0.1361 - val_accuracy: 0.9487 - lr: 0.0010\n","Epoch 10/10\n","281/281 [==============================] - 10s 36ms/step - loss: 0.1286 - accuracy: 0.9489 - val_loss: 0.1545 - val_accuracy: 0.9362 - lr: 0.0010\n","1122/1122 [==============================] - 10s 9ms/step - loss: 0.1213 - accuracy: 0.9460\n","Model accuracy on training data -  94.59956288337708 %\n","281/281 [==============================] - 2s 9ms/step - loss: 0.1545 - accuracy: 0.9362\n","Model accuracy on testing data -  93.62460970878601 %\n","281/281 [==============================] - 3s 8ms/step\n","              precision    recall  f1-score   support\n","\n","        Fake      0.903     0.989     0.944      4868\n","        Real      0.986     0.873     0.926      4104\n","\n","    accuracy                          0.936      8972\n","   macro avg      0.944     0.931     0.935      8972\n","weighted avg      0.941     0.936     0.936      8972\n","\n","Specificity 0.9893179950698439\n","Model dl_model saved!\n"]}]},{"cell_type":"code","source":["train_and_evalute_dl_model(wellfake_data, 'cleaned_text', model_type='bi')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nrrIIP7oYIAP","executionInfo":{"status":"ok","timestamp":1681439800439,"user_tz":-180,"elapsed":206393,"user":{"displayName":"Alunat","userId":"04744058558773087828"}},"outputId":"166ea1dd-cabf-4d2a-a4d2-948c54bb8baf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-97-e65ffe719b60>:1: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n","  train_and_evalute_dl_model(wellfake_data, 'cleaned_text', model_type='bi')\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"sequential_31\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_25 (Embedding)    (None, 300, 100)          1000000   \n","                                                                 \n"," bidirectional_20 (Bidirecti  (None, 300, 128)         84480     \n"," onal)                                                           \n","                                                                 \n"," bidirectional_21 (Bidirecti  (None, 64)               41216     \n"," onal)                                                           \n","                                                                 \n"," dense_46 (Dense)            (None, 64)                4160      \n","                                                                 \n"," dense_47 (Dense)            (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 1,129,921\n","Trainable params: 129,921\n","Non-trainable params: 1,000,000\n","_________________________________________________________________\n","Epoch 1/10\n","281/281 [==============================] - 21s 53ms/step - loss: 0.3962 - accuracy: 0.8188 - val_loss: 0.2864 - val_accuracy: 0.8768 - lr: 0.0010\n","Epoch 2/10\n","281/281 [==============================] - 13s 48ms/step - loss: 0.2993 - accuracy: 0.8717 - val_loss: 0.3394 - val_accuracy: 0.8464 - lr: 0.0010\n","Epoch 3/10\n","281/281 [==============================] - 13s 47ms/step - loss: 0.2624 - accuracy: 0.8874 - val_loss: 0.3112 - val_accuracy: 0.8652 - lr: 0.0010\n","Epoch 4/10\n","281/281 [==============================] - 13s 47ms/step - loss: 0.2269 - accuracy: 0.9033 - val_loss: 0.1999 - val_accuracy: 0.9162 - lr: 0.0010\n","Epoch 5/10\n","281/281 [==============================] - 13s 47ms/step - loss: 0.1914 - accuracy: 0.9205 - val_loss: 0.2200 - val_accuracy: 0.9077 - lr: 0.0010\n","Epoch 6/10\n","281/281 [==============================] - 13s 47ms/step - loss: 0.1690 - accuracy: 0.9285 - val_loss: 0.1637 - val_accuracy: 0.9331 - lr: 0.0010\n","Epoch 7/10\n","281/281 [==============================] - 13s 47ms/step - loss: 0.1491 - accuracy: 0.9399 - val_loss: 0.1464 - val_accuracy: 0.9403 - lr: 0.0010\n","Epoch 8/10\n","281/281 [==============================] - 13s 47ms/step - loss: 0.1338 - accuracy: 0.9453 - val_loss: 0.1497 - val_accuracy: 0.9390 - lr: 0.0010\n","Epoch 9/10\n","281/281 [==============================] - 13s 47ms/step - loss: 0.1276 - accuracy: 0.9480 - val_loss: 0.1602 - val_accuracy: 0.9349 - lr: 0.0010\n","Epoch 10/10\n","281/281 [==============================] - 13s 47ms/step - loss: 0.1146 - accuracy: 0.9544 - val_loss: 0.1428 - val_accuracy: 0.9430 - lr: 0.0010\n","1122/1122 [==============================] - 16s 15ms/step - loss: 0.0970 - accuracy: 0.9608\n","Model accuracy on training data -  96.07924818992615 %\n","281/281 [==============================] - 4s 15ms/step - loss: 0.1428 - accuracy: 0.9430\n","Model accuracy on testing data -  94.30450201034546 %\n","281/281 [==============================] - 5s 14ms/step\n","              precision    recall  f1-score   support\n","\n","        Fake      0.970     0.924     0.946      4868\n","        Real      0.915     0.966     0.939      4104\n","\n","    accuracy                          0.943      8972\n","   macro avg      0.942     0.945     0.943      8972\n","weighted avg      0.944     0.943     0.943      8972\n","\n","Specificity 0.9239934264585046\n"]}]},{"cell_type":"code","source":["train_and_evalute_dl_model(wellfake_data, 'cleaned_title', model_type='bi')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Qa-v0o03YH1M","executionInfo":{"status":"ok","timestamp":1681440020228,"user_tz":-180,"elapsed":200952,"user":{"displayName":"Alunat","userId":"04744058558773087828"}},"outputId":"ef615d22-1324-4248-8d18-b5a0385b0ea6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-98-308d6b9be4a7>:1: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n","  train_and_evalute_dl_model(wellfake_data, 'cleaned_title', model_type='bi')\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"sequential_32\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_26 (Embedding)    (None, 300, 100)          1000000   \n","                                                                 \n"," bidirectional_22 (Bidirecti  (None, 300, 128)         84480     \n"," onal)                                                           \n","                                                                 \n"," bidirectional_23 (Bidirecti  (None, 64)               41216     \n"," onal)                                                           \n","                                                                 \n"," dense_48 (Dense)            (None, 64)                4160      \n","                                                                 \n"," dense_49 (Dense)            (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 1,129,921\n","Trainable params: 129,921\n","Non-trainable params: 1,000,000\n","_________________________________________________________________\n","Epoch 1/10\n","281/281 [==============================] - 21s 52ms/step - loss: 0.3898 - accuracy: 0.8146 - val_loss: 0.3250 - val_accuracy: 0.8488 - lr: 0.0010\n","Epoch 2/10\n","281/281 [==============================] - 13s 48ms/step - loss: 0.3073 - accuracy: 0.8623 - val_loss: 0.3026 - val_accuracy: 0.8630 - lr: 0.0010\n","Epoch 3/10\n","281/281 [==============================] - 13s 47ms/step - loss: 0.2808 - accuracy: 0.8764 - val_loss: 0.2886 - val_accuracy: 0.8700 - lr: 0.0010\n","Epoch 4/10\n","281/281 [==============================] - 13s 47ms/step - loss: 0.2619 - accuracy: 0.8859 - val_loss: 0.2747 - val_accuracy: 0.8772 - lr: 0.0010\n","Epoch 5/10\n","281/281 [==============================] - 13s 47ms/step - loss: 0.2456 - accuracy: 0.8939 - val_loss: 0.2686 - val_accuracy: 0.8844 - lr: 0.0010\n","Epoch 6/10\n","281/281 [==============================] - 13s 47ms/step - loss: 0.2296 - accuracy: 0.9013 - val_loss: 0.2690 - val_accuracy: 0.8835 - lr: 0.0010\n","Epoch 7/10\n","281/281 [==============================] - 13s 47ms/step - loss: 0.2171 - accuracy: 0.9072 - val_loss: 0.2609 - val_accuracy: 0.8885 - lr: 0.0010\n","Epoch 8/10\n","281/281 [==============================] - 13s 47ms/step - loss: 0.2033 - accuracy: 0.9140 - val_loss: 0.2668 - val_accuracy: 0.8866 - lr: 0.0010\n","Epoch 9/10\n","281/281 [==============================] - 13s 47ms/step - loss: 0.1920 - accuracy: 0.9188 - val_loss: 0.2743 - val_accuracy: 0.8863 - lr: 0.0010\n","Epoch 10/10\n","281/281 [==============================] - 13s 47ms/step - loss: 0.1822 - accuracy: 0.9245 - val_loss: 0.2728 - val_accuracy: 0.8843 - lr: 0.0010\n","1122/1122 [==============================] - 17s 15ms/step - loss: 0.1420 - accuracy: 0.9457\n","Model accuracy on training data -  94.57448720932007 %\n","281/281 [==============================] - 4s 14ms/step - loss: 0.2728 - accuracy: 0.8843\n","Model accuracy on testing data -  88.43067288398743 %\n","281/281 [==============================] - 5s 14ms/step\n","              precision    recall  f1-score   support\n","\n","        Fake      0.898     0.888     0.893      4868\n","        Real      0.869     0.880     0.874      4104\n","\n","    accuracy                          0.884      8972\n","   macro avg      0.883     0.884     0.884      8972\n","weighted avg      0.884     0.884     0.884      8972\n","\n","Specificity 0.8880443714050945\n"]}]},{"cell_type":"code","source":["train_and_evalute_dl_model(wellfake_data, 'cleaned_combined', model_type='bi', filename='wellfake_bilstm_combined')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EqN1yKGOYHm7","executionInfo":{"status":"ok","timestamp":1683399780971,"user_tz":-180,"elapsed":214558,"user":{"displayName":"Alunat","userId":"04744058558773087828"}},"outputId":"e152ec43-73e3-4d34-963b-ec8542372b37"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-22-687410555f58>:1: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n","  train_and_evalute_dl_model(wellfake_data, 'cleaned_combined', model_type='bi', filename='wellfake_bilstm_combined')\n"]},{"output_type":"stream","name":"stdout","text":["Model: \"sequential_5\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," embedding_3 (Embedding)     (None, 300, 100)          1000000   \n","                                                                 \n"," bidirectional (Bidirectiona  (None, 300, 128)         84480     \n"," l)                                                              \n","                                                                 \n"," bidirectional_1 (Bidirectio  (None, 64)               41216     \n"," nal)                                                            \n","                                                                 \n"," dense_6 (Dense)             (None, 64)                4160      \n","                                                                 \n"," dense_7 (Dense)             (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 1,129,921\n","Trainable params: 129,921\n","Non-trainable params: 1,000,000\n","_________________________________________________________________\n","Epoch 1/10\n","281/281 [==============================] - 21s 52ms/step - loss: 0.3894 - accuracy: 0.8210 - val_loss: 0.2946 - val_accuracy: 0.8739 - lr: 0.0010\n","Epoch 2/10\n","281/281 [==============================] - 13s 47ms/step - loss: 0.3025 - accuracy: 0.8707 - val_loss: 0.2647 - val_accuracy: 0.8921 - lr: 0.0010\n","Epoch 3/10\n","281/281 [==============================] - 13s 47ms/step - loss: 0.2644 - accuracy: 0.8868 - val_loss: 0.2297 - val_accuracy: 0.9060 - lr: 0.0010\n","Epoch 4/10\n","281/281 [==============================] - 13s 47ms/step - loss: 0.2854 - accuracy: 0.8793 - val_loss: 0.2132 - val_accuracy: 0.9137 - lr: 0.0010\n","Epoch 5/10\n","281/281 [==============================] - 13s 47ms/step - loss: 0.2052 - accuracy: 0.9153 - val_loss: 0.1937 - val_accuracy: 0.9198 - lr: 0.0010\n","Epoch 6/10\n","281/281 [==============================] - 13s 47ms/step - loss: 0.1744 - accuracy: 0.9283 - val_loss: 0.1536 - val_accuracy: 0.9378 - lr: 0.0010\n","Epoch 7/10\n","281/281 [==============================] - 13s 47ms/step - loss: 0.1535 - accuracy: 0.9378 - val_loss: 0.1694 - val_accuracy: 0.9318 - lr: 0.0010\n","Epoch 8/10\n","281/281 [==============================] - 13s 47ms/step - loss: 0.1394 - accuracy: 0.9435 - val_loss: 0.1472 - val_accuracy: 0.9440 - lr: 0.0010\n","Epoch 9/10\n","281/281 [==============================] - 13s 47ms/step - loss: 0.1256 - accuracy: 0.9494 - val_loss: 0.1528 - val_accuracy: 0.9424 - lr: 0.0010\n","Epoch 10/10\n","281/281 [==============================] - 13s 47ms/step - loss: 0.1202 - accuracy: 0.9514 - val_loss: 0.1444 - val_accuracy: 0.9439 - lr: 0.0010\n","1122/1122 [==============================] - 16s 15ms/step - loss: 0.1130 - accuracy: 0.9523\n","Model accuracy on training data -  95.22933959960938 %\n","281/281 [==============================] - 4s 15ms/step - loss: 0.1444 - accuracy: 0.9439\n","Model accuracy on testing data -  94.39367055892944 %\n","281/281 [==============================] - 5s 14ms/step\n","              precision    recall  f1-score   support\n","\n","        Fake      0.915     0.988     0.950      4868\n","        Real      0.985     0.891     0.936      4104\n","\n","    accuracy                          0.944      8972\n","   macro avg      0.950     0.940     0.943      8972\n","weighted avg      0.947     0.944     0.944      8972\n","\n","Specificity 0.9884963023829088\n","Model wellfake_bilstm_combined saved!\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.5"},"vscode":{"interpreter":{"hash":"81794d4967e6c3204c66dcd87b604927b115b27c00565d3d43f05ba2f3a2cb0d"}},"gpuClass":"premium"},"nbformat":4,"nbformat_minor":0}